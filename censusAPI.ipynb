{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#All I've done so far is prep the OG dataset for gathering census data.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aiDXYnn7hHVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pgeocode"
      ],
      "metadata": {
        "id": "mFYez3fspQQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pgeocode\n",
        "import requests"
      ],
      "metadata": {
        "id": "H-1UloHDvswU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining all functions for use with census API.\n",
        "#retrieving city and state for each zip code.\n",
        "def getCityStateByZip(zipCode):\n",
        "    location = nomi.query_postal_code(zipCode)\n",
        "    if location is not None and pd.notna(location.place_name) and pd.notna(location.state_name):\n",
        "        return location.place_name.lower().strip(), location.state_name.upper().strip()\n",
        "    else:\n",
        "        return None, None\n",
        "#converting state names into their abbreviations.\n",
        "def convertStateToAbbrv(stateName):\n",
        "    states = {\"ALABAMA\": \"AL\", \"ALASKA\": \"AK\", \"ARIZONA\": \"AZ\", \"ARKANSAS\": \"AR\", \"CALIFORNIA\": \"CA\", \"COLORADO\": \"CO\", \"CONNECTICUT\": \"CT\", \"DELAWARE\": \"DE\", \"FLORIDA\": \"FL\",\n",
        "              \"GEORGIA\": \"GA\", \"HAWAII\": \"HI\", \"IDAHO\": \"ID\", \"ILLINOIS\": \"IL\", \"INDIANA\": \"IN\", \"IOWA\": \"IA\", \"KANSAS\": \"KS\", \"KENTUCKY\": \"KY\", \"LOUISIANA\": \"LA\", \"MAINE\": \"ME\",\n",
        "              \"MARYLAND\": \"MD\", \"MASSACHUSETTS\": \"MA\", \"MICHIGAN\": \"MI\", \"MINNESOTA\": \"MN\", \"MISSISSIPPI\": \"MS\", \"MISSOURI\": \"MO\", \"MONTANA\": \"MT\", \"NEBRASKA\": \"NE\", \"NEVADA\": \"NV\",\n",
        "              \"NEW HAMPSHIRE\": \"NH\", \"NEW JERSEY\": \"NJ\", \"NEW MEXICO\": \"NM\", \"NEW YORK\": \"NY\", \"NORTH CAROLINA\": \"NC\", \"NORTH DAKOTA\": \"ND\", \"OHIO\": \"OH\", \"OKLAHOMA\": \"OK\", \"OREGON\": \"OR\",\n",
        "              \"PENNSYLVANIA\": \"PA\", \"RHODE ISLAND\": \"RI\", \"SOUTH CAROLINA\": \"SC\", \"SOUTH DAKOTA\": \"SD\", \"TENNESSEE\": \"TN\", \"TEXAS\": \"TX\", \"UTAH\": \"UT\", \"VERMONT\": \"VT\", \"VIRGINIA\": \"VA\",\n",
        "              \"WASHINGTON\": \"WA\", \"WEST VIRGINIA\": \"WV\", \"WISCONSIN\": \"WI\", \"WYOMING\": \"WY\"}\n",
        "    return states.get(stateName.upper(), None)\n",
        "#getting FIPS codes using the census gazetteer files, defining descriptors for location names, splitting geoid column after first two numbers.\n",
        "def getFIPSCodes(city, state):\n",
        "    if not pd.isna(city) and not pd.isna(state):\n",
        "        city = city.strip().lower()\n",
        "        state = state.strip().upper()\n",
        "        descriptors = [\"\", \" city\", \" town\", \" cdp\", \" township\", \"borough\", \"village\"]\n",
        "        for desc in descriptors:\n",
        "            match = gazetteer[(gazetteer[\"NAME\"].str.contains(rf\"^{city}{desc}$\", na=False, regex=True)) & (gazetteer[\"USPS\"] == state)]\n",
        "            if not match.empty:\n",
        "                geoID = match.iloc[0][\"GEOID\"]\n",
        "                stateFIPS = geoID[:2]\n",
        "                placeFIPS = geoID[2:]\n",
        "                return stateFIPS, placeFIPS\n",
        "    return None, None\n",
        "#querying the census API to collect the variables defined below.\n",
        "def queryCensusAPI(stateFIPS, placeFIPS):\n",
        "    params = {\"get\": \",\".join(variables), \"for\": f\"place:{placeFIPS}\", \"in\": f\"state:{stateFIPS}\", \"key\": apiKey}\n",
        "    response = requests.get(baseURL, params=params)"
      ],
      "metadata": {
        "id": "MuzAOKlwrgan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the texas roadhouse and census gazetteer datasets, extracting the zip code from the state column,\n",
        "#and initializing pgeocode for zip codes.\n",
        "trDf = pd.read_csv(\"texasRoadhouseLocations.csv\")\n",
        "gazetteer = pd.read_csv(\"2020censusPlaces.txt\", delimiter=\"\\t\", dtype=str)\n",
        "trDf[\"ZIP\"] = trDf[\"state\"].str.split().str[1]\n",
        "nomi = pgeocode.Nominatim(\"us\")\n",
        "#populating city and state using zip codes and converting state names to abbrevations.\n",
        "trDf[\"city\"] = trDf[\"ZIP\"].apply(lambda z: getCityStateByZip(z)[0])\n",
        "trDf[\"state\"] = trDf[\"ZIP\"].apply(lambda z: getCityStateByZip(z)[1])\n",
        "trDf[\"state\"] = trDf[\"state\"].apply(convertStateToAbbrv)\n",
        "#normalizing gazetteer data, adding FIPS columns.\n",
        "gazetteer[\"NAME\"] = gazetteer[\"NAME\"].str.strip().str.lower()\n",
        "gazetteer[\"USPS\"] = gazetteer[\"USPS\"].str.strip().str.upper()\n",
        "trDf[\"stateFIPS\"] = None\n",
        "trDf[\"placeFIPS\"] = None"
      ],
      "metadata": {
        "id": "kc21t9h_mOpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#populating FIPS codes for city and state and saving the output to trFIPS.\n",
        "for index, row in trDf.iterrows():\n",
        "    city = row[\"city\"]\n",
        "    state = row[\"state\"]\n",
        "    if state in gazetteer[\"USPS\"].values:\n",
        "        stateFIPS, placeFIPS = getFIPSCodes(city, state)\n",
        "    else:\n",
        "        stateFIPS, placeFIPS = None, None\n",
        "    trDf.at[index, \"stateFIPS\"] = stateFIPS\n",
        "    trDf.at[index, \"placeFIPS\"] = placeFIPS\n",
        "\n",
        "trDf.to_csv(\"trFIPS.csv\", index=False)"
      ],
      "metadata": {
        "id": "zzA2NkZddfvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining api credentials, URL, data to be obtained (variables), and descriptive column names (columnMapping).\n",
        "apiKey = \"apiKey goes here\"\n",
        "baseURL = \"https://api.census.gov/data/2020/acs/acs5\"\n",
        "variables = [\"NAME\",\"B01001_001E\", \"B01001_002E\", \"B01001_026E\", \"B01002_001E\", \"B01002_002E\", \"B01002_003E\", \"B02001_002E\", \"B02001_003E\",\n",
        "             \"B02001_005E\", \"B03001_003E\", \"B19013_001E\", \"B19001_002E\", \"B19001_003E\", \"B19001_004E\", \"B19301_001E\", \"B17001_002E\", \"B25064_001E\",\n",
        "             \"B25002_001E\", \"B25003_002E\", \"B25003_003E\", \"B25077_001E\", \"B25031_001E\", \"B25035_001E\", \"B15003_001E\", \"B15003_017E\", \"B15003_022E\",\n",
        "             \"B15003_023E\", \"B23025_003E\", \"C24010_001E\", \"B24011_004E\", \"B24011_034E\", \"B03002_012E\", \"B03002_004E\", \"B03002_006E\", \"B08301_001E\",\n",
        "             \"B08013_001E\", \"B08201_001E\", \"B18101_001E\", \"B27010_001E\", \"B11001_001E\", \"B11003_001E\", \"B11009_001E\", \"B12001_001E\"]\n",
        "columnMapping = {\"NAME\": \"placeName\", \"B01001_001E\": \"totalPopulation\", \"B01001_002E\": \"malePopulation\", \"B01001_026E\": \"femalePopulation\", \"B01002_001E\": \"medianAge\",\n",
        "                 \"B01002_002E\": \"medianAgeMale\", \"B01002_003E\": \"medianAgeFemale\", \"B02001_002E\": \"whitePopulation\", \"B02001_003E\": \"blackPopulation\", \"B02001_005E\": \"asianPopulation\",\n",
        "                 \"B03001_003E\": \"hispanicPopulation\", \"B19013_001E\": \"medianHouseholdIncome\", \"B19001_002E\": \"incomeBelow10k\", \"B19001_003E\": \"income10kTo15k\",\n",
        "                 \"B19001_004E\": \"income15kTo25k\", \"B19301_001E\": \"perCapitaIncome\", \"B17001_002E\": \"populationBelowPoverty\", \"B25064_001E\": \"medianGrossRent\",\n",
        "                 \"B25002_001E\": \"totalHousingUnits\", \"B25003_002E\": \"ownerOccupiedHousingUnits\", \"B25003_003E\": \"renterOccupiedHousingUnits\", \"B25077_001E\": \"medianHomeValue\",\n",
        "                 \"B25031_001E\": \"medianMonthlyHousingCosts\", \"B25035_001E\": \"medianYearStructureBuilt\", \"B15003_001E\": \"totalEducationPopulation\", \"B15003_017E\": \"bachelorsDegree\",\n",
        "                 \"B15003_022E\": \"mastersDegree\", \"B15003_023E\": \"doctorateDegree\", \"B23025_003E\": \"employedPopulation\", \"C24010_001E\": \"occupationData\",\n",
        "                 \"B24011_004E\": \"managementOccupation\", \"B24011_034E\": \"serviceOccupation\", \"B03002_012E\": \"foreignBornPopulation\", \"B03002_004E\": \"notHispanicWhitePopulation\",\n",
        "                 \"B03002_006E\": \"notHispanicBlackPopulation\", \"B08301_001E\": \"commuters\", \"B08013_001E\": \"meanTravelTime\", \"B08201_001E\": \"carAvailability\",\n",
        "                 \"B18101_001E\": \"disabilityPopulation\", \"B27010_001E\": \"healthInsurancePopulation\", \"B11001_001E\": \"householdPopulation\", \"B11003_001E\": \"singleParentHouseholds\",\n",
        "                 \"B11009_001E\": \"unmarriedPartners\", \"B12001_001E\": \"marriedPopulation\"}\n",
        "results = []"
      ],
      "metadata": {
        "id": "g1041U4bqGqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the trFIPS dataset created above and requesting data from the API.\n",
        "trhDf = pd.read_csv(\"trFIPS.csv\")\n",
        "for _, row in trhDf.iterrows():\n",
        "    try:\n",
        "        if pd.isna(row[\"stateFIPS\"]) or pd.isna(row[\"placeFIPS\"]):\n",
        "            print(f\"Skipping row with missing FIPS: {row}\")\n",
        "            continue\n",
        "        stateFIPS = str(int(row[\"stateFIPS\"])).zfill(2)\n",
        "        placeFIPS = str(int(row[\"placeFIPS\"])).zfill(5)\n",
        "        data = queryCensusAPI(stateFIPS, placeFIPS)\n",
        "        header = data[0]\n",
        "        for item in data[1:]:\n",
        "            rowData = {\"stateFIPS\": stateFIPS, \"placeFIPS\": placeFIPS}\n",
        "            rowData.update({header[i]: item[i] for i in range(len(header))})\n",
        "            results.append(rowData)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row: {row}, Error: {e}\")\n",
        "#saving the data to a dataframe, renaming the columns as defined above and saving the results to censusData.csv.\n",
        "censusData = pd.DataFrame(results)\n",
        "censusData.rename(columns=columnMapping, inplace=True)\n",
        "censusData.to_csv(\"censusData.csv\", index=False)"
      ],
      "metadata": {
        "id": "Wnvfch1anDdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the census dataset.\n",
        "censusDf = pd.read_csv(\"censusData.csv\")  # Demographic data"
      ],
      "metadata": {
        "id": "r2XgYEJRHZB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ensuring stateFIPS and placeFIPS are integers in both texas roadhouse and census data.\n",
        "trhDf[\"stateFIPS\"] = trhDf[\"stateFIPS\"].astype(\"Int64\")\n",
        "trhDf[\"placeFIPS\"] = trhDf[\"placeFIPS\"].astype(\"Int64\")\n",
        "censusDf[\"stateFIPS\"] = censusDf[\"stateFIPS\"].astype(\"Int64\")\n",
        "censusDf[\"placeFIPS\"] = censusDf[\"placeFIPS\"].astype(\"Int64\")\n",
        "#performing an inner join to merge the datasets on stateFIPS and placeFIPS.\n",
        "df = pd.merge(trhDf, censusDf, on=[\"stateFIPS\", \"placeFIPS\"], how=\"inner\")\n",
        "#dropping duplicate rows and saving the cleaned dataset as trhCensusDf.csv.\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Number of rows after dropping duplicates: {len(df)}\")\n",
        "df.to_csv(\"trhCensusDf.csv\", index=False)"
      ],
      "metadata": {
        "id": "Ogpgo-0sYnWI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}